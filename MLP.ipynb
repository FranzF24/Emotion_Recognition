{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "\n",
    "from skimage import io, color, transform\n",
    "from skimage.feature import hog\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\gonza\\AppData\\Local\\Temp\\ipykernel_14624\\488994593.py:1: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  gray_matrix = np.load('DatosDF\\gray_matrix.npy', allow_pickle=True)\n",
      "C:\\Users\\gonza\\AppData\\Local\\Temp\\ipykernel_14624\\488994593.py:2: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  hog = np.load('DatosDF\\hog.npy', allow_pickle=True)\n",
      "C:\\Users\\gonza\\AppData\\Local\\Temp\\ipykernel_14624\\488994593.py:3: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  estados = np.load('DatosDF\\estados.npy', allow_pickle=True)\n",
      "C:\\Users\\gonza\\AppData\\Local\\Temp\\ipykernel_14624\\488994593.py:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  label = np.load('DatosDF\\labels.npy', allow_pickle=True)\n"
     ]
    }
   ],
   "source": [
    "gray_matrix = np.load('DatosDF\\gray_matrix.npy', allow_pickle=True)\n",
    "hog = np.load('DatosDF\\hog.npy', allow_pickle=True)\n",
    "estados = np.load('DatosDF\\estados.npy', allow_pickle=True)\n",
    "label = np.load('DatosDF\\labels.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'gray_matrix': gray_matrix,'hog': hog,'estados': estados,'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gray_matrix</th>\n",
       "      <th>hog</th>\n",
       "      <th>estados</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[175, 166, 185, 198, 202, 213, 212, 209, 210,...</td>\n",
       "      <td>[0.20444939, 0.034390625, 0.026585897, 0.01487...</td>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[26, 29, 30, 35, 45, 60, 108, 145, 161, 161, ...</td>\n",
       "      <td>[0.46974203, 0.15378156, 0.0056655, 0.0, 0.002...</td>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[[17, 18, 19, 19, 17, 15, 16, 17, 18, 20, 18, ...</td>\n",
       "      <td>[0.16117984, 0.10060929, 0.12280247, 0.0026138...</td>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 13, 37, ...</td>\n",
       "      <td>[0.17848918, 0.014774916, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[[254, 254, 254, 254, 254, 254, 254, 254, 254,...</td>\n",
       "      <td>[0.025827257, 0.01296422, 0.020755643, 0.0, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35863</th>\n",
       "      <td>[[9, 38, 69, 99, 86, 102, 111, 105, 65, 58, 64...</td>\n",
       "      <td>[0.23134665, 0.3235038, 0.13396424, 0.05265233...</td>\n",
       "      <td>1</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>[[253, 253, 254, 253, 170, 101, 105, 102, 85, ...</td>\n",
       "      <td>[0.4190711, 0.32569548, 0.0045682807, 0.002312...</td>\n",
       "      <td>1</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>[[252, 247, 146, 93, 94, 89, 99, 94, 93, 83, 9...</td>\n",
       "      <td>[0.32172725, 0.29283354, 0.09000543, 0.0720573...</td>\n",
       "      <td>1</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35878</th>\n",
       "      <td>[[33, 44, 49, 40, 35, 28, 23, 14, 9, 16, 17, 5...</td>\n",
       "      <td>[0.20763314, 0.31089163, 0.1581842, 0.02511550...</td>\n",
       "      <td>1</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>[[124, 129, 125, 123, 129, 128, 127, 128, 131,...</td>\n",
       "      <td>[0.20560372, 0.04748373, 0.03934206, 0.0998374...</td>\n",
       "      <td>1</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4611 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             gray_matrix  \\\n",
       "16     [[175, 166, 185, 198, 202, 213, 212, 209, 210,...   \n",
       "23     [[26, 29, 30, 35, 45, 60, 108, 145, 161, 161, ...   \n",
       "30     [[17, 18, 19, 19, 17, 15, 16, 17, 18, 20, 18, ...   \n",
       "31     [[0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 13, 37, ...   \n",
       "45     [[254, 254, 254, 254, 254, 254, 254, 254, 254,...   \n",
       "...                                                  ...   \n",
       "35863  [[9, 38, 69, 99, 86, 102, 111, 105, 65, 58, 64...   \n",
       "35869  [[253, 253, 254, 253, 170, 101, 105, 102, 85, ...   \n",
       "35875  [[252, 247, 146, 93, 94, 89, 99, 94, 93, 83, 9...   \n",
       "35878  [[33, 44, 49, 40, 35, 28, 23, 14, 9, 16, 17, 5...   \n",
       "35884  [[124, 129, 125, 123, 129, 128, 127, 128, 131,...   \n",
       "\n",
       "                                                     hog  estados     label  \n",
       "16     [0.20444939, 0.034390625, 0.026585897, 0.01487...        1     angry  \n",
       "23     [0.46974203, 0.15378156, 0.0056655, 0.0, 0.002...        1     angry  \n",
       "30     [0.16117984, 0.10060929, 0.12280247, 0.0026138...        1     angry  \n",
       "31     [0.17848918, 0.014774916, 0.0, 0.0, 0.0, 0.0, ...        1     angry  \n",
       "45     [0.025827257, 0.01296422, 0.020755643, 0.0, 0....        1     angry  \n",
       "...                                                  ...      ...       ...  \n",
       "35863  [0.23134665, 0.3235038, 0.13396424, 0.05265233...        1  surprise  \n",
       "35869  [0.4190711, 0.32569548, 0.0045682807, 0.002312...        1  surprise  \n",
       "35875  [0.32172725, 0.29283354, 0.09000543, 0.0720573...        1  surprise  \n",
       "35878  [0.20763314, 0.31089163, 0.1581842, 0.02511550...        1  surprise  \n",
       "35884  [0.20560372, 0.04748373, 0.03934206, 0.0998374...        1  surprise  \n",
       "\n",
       "[4611 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfxusar = df[df['estados'] == 1]\n",
    "elresto = df[df['estados'] == 0]\n",
    "dfxusar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dfxusar['hog'].values.tolist())\n",
    "y = dfxusar['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'activation' parameter of MLPClassifier must be a str among {'logistic', 'identity', 'relu', 'tanh'}. Got 'softmax' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\MachinLerni - Rostros\\MLP.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/MachinLerni%20-%20Rostros/MLP.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mlp \u001b[39m=\u001b[39m MLPClassifier(hidden_layer_sizes\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m,),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/MachinLerni%20-%20Rostros/MLP.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                     activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/MachinLerni%20-%20Rostros/MLP.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/MachinLerni%20-%20Rostros/MLP.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     n_iter_no_change\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/MachinLerni%20-%20Rostros/MLP.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/MachinLerni%20-%20Rostros/MLP.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m mlp\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[0;32m   1141\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1142\u001b[0m )\n\u001b[0;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1145\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[0;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:638\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    631\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \n\u001b[0;32m    633\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m     validate_parameter_constraints(\n\u001b[0;32m    639\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[0;32m    640\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    641\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    642\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[0;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m     )\n\u001b[1;32m---> 96\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'activation' parameter of MLPClassifier must be a str among {'logistic', 'identity', 'relu', 'tanh'}. Got 'softmax' instead."
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                    activation='logistic',\n",
    "                    solver='sgd',\n",
    "                    alpha=0,\n",
    "                    learning_rate='constant',\n",
    "                    max_iter=10000,\n",
    "                    tol=1e-6,\n",
    "                    verbose=True,\n",
    "                    momentum=0,\n",
    "                    n_iter_no_change=25,\n",
    "                    random_state=42)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "&&time\n",
    "y_pred_e= mlp.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_e)\n",
    "print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "print(classification_report(y_train, y_pred_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión del modelo: 0.8695770065075922\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       angry       0.84      0.84      0.84       462\n",
    "     disgust       0.76      0.67      0.71       435\n",
    "        fear       0.82      0.78      0.80       579\n",
    "       happy       0.95      0.99      0.97       650\n",
    "     neutral       0.93      0.94      0.94       622\n",
    "         sad       0.80      0.85      0.82       467\n",
    "    surprise       0.92      0.95      0.94       473\n",
    "\n",
    "    accuracy                           0.87      3688\n",
    "   macro avg       0.86      0.86      0.86      3688\n",
    "weighted avg       0.87      0.87      0.87      3688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión del modelo: 0.7908992416034669\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       angry       0.67      0.69      0.68       101\n",
    "     disgust       0.56      0.48      0.52       112\n",
    "        fear       0.73      0.77      0.75       156\n",
    "       happy       0.92      0.97      0.94       149\n",
    "     neutral       0.89      0.88      0.88       153\n",
    "         sad       0.73      0.74      0.74       119\n",
    "    surprise       0.92      0.89      0.90       133\n",
    "\n",
    "    accuracy                           0.79       923\n",
    "   macro avg       0.77      0.78      0.77       923\n",
    "weighted avg       0.79      0.79      0.79       923\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Conjunto Pequeño] GridSearch - Optimizacion de parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define el modelo de Red Neuronal\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                    activation='logistic',\n",
    "                    solver='sgd',\n",
    "                    alpha=0,\n",
    "                    learning_rate='constant',\n",
    "                    max_iter=10000,\n",
    "                    tol=1e-4,\n",
    "                    verbose=True,\n",
    "                    momentum=0,\n",
    "                    n_iter_no_change=25,\n",
    "                    random_state=42)\n",
    "\n",
    "# Define una cuadrícula de hiperparámetros que deseas explorar\n",
    "param_grid = {\n",
    "    'max_iter': [500,1000,2000],\n",
    "    'learning_rate_init': [0.1,0.001,0.0001],\n",
    "    'batch_size': [32,128,512]\n",
    "}\n",
    "\n",
    "# Realiza la búsqueda en cuadrícula con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, scoring='accuracy', verbose=10,n_jobs=8)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los mejores hiperparámetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "\n",
    "# Entrena el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en el conjunto de prueba\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejores hiperparámetros: \n",
    "- 'batch_size': 512\n",
    "- 'learning_rate_init': 0.1\n",
    "- 'max_iter': 1000\n",
    "\n",
    "Precisión del modelo: 0.8266522210184182\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       angry       0.72      0.78      0.75       101\n",
    "     disgust       0.70      0.61      0.65       112\n",
    "        fear       0.80      0.83      0.81       156\n",
    "       happy       0.97      0.98      0.97       149\n",
    "     neutral       0.86      0.88      0.87       153\n",
    "         sad       0.72      0.72      0.72       119\n",
    "    surprise       0.93      0.91      0.92       133\n",
    "\n",
    "    accuracy                           0.83       923\n",
    "   macro avg       0.82      0.81      0.81       923\\\n",
    "weighted avg       0.83      0.83      0.83       923\\\n",
    "\n",
    "CPU times: total: 13min 54s\\\n",
    "Wall time: 3h 22min 48s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo - con conocimiento de causa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gonza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\gonza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gonza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 753, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gonza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 496, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\gonza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.42140554 0.8123628  0.80097885 0.18328902 0.80883645 0.80640147\n",
      " 0.42177362 0.81235434 0.79826441        nan 0.79826367 0.80856655\n",
      "        nan 0.79799451 0.80883976        nan 0.8015157  0.80883976\n",
      " 0.46262847 0.80558773 0.78362438 0.40973146 0.8099223  0.76355657\n",
      " 0.44308318 0.80612679 0.7879663         nan 0.78742025 0.79663949\n",
      "        nan 0.78985854 0.80016657        nan 0.78252419 0.79853798\n",
      " 0.56298147 0.78146481 0.75841414 0.4786202  0.79664096 0.74349024\n",
      " 0.47429372 0.78443812 0.74809838 0.17380614 0.78742025 0.76925425\n",
      " 0.16676007 0.78768978 0.7790199  0.17517475 0.78200608 0.76167389\n",
      " 0.81263637 0.8120951  0.78552397 0.80991826 0.81154942 0.77793001\n",
      " 0.81046063 0.81778138 0.76951826 0.80178965 0.79880972 0.21066471\n",
      " 0.8009748  0.80043206 0.29229536 0.79935246 0.80070711 0.28850537\n",
      " 0.80911444 0.80097811 0.74784356 0.81208959 0.80639927 0.72504183\n",
      " 0.8080205  0.79094844 0.73264461 0.79365405 0.78199321 0.18275143\n",
      " 0.79799487 0.71305777 0.22150482 0.79690645 0.65717348 0.20229893\n",
      " 0.78660872 0.78173214 0.5415046  0.79393094 0.76138119 0.4069512\n",
      " 0.77874155 0.76084397 0.46401915 0.25137432 0.1965836  0.1960416\n",
      " 0.46261633 0.30501962 0.19061051 0.30963549 0.2643431  0.17624737\n",
      " 0.81968208 0.81100852 0.80341861 0.81398955 0.80883903 0.80504572\n",
      " 0.82022114 0.81642416 0.80612643 0.82944737 0.82564855 0.81019257\n",
      " 0.82700577 0.81453597 0.8055903  0.82185414 0.81778653 0.8093814\n",
      " 0.81914301 0.80884123 0.78769567 0.81155053 0.81344902 0.77875368\n",
      " 0.81344203 0.8088302  0.78037418 0.8164271  0.81290664 0.80260449\n",
      " 0.81887385 0.81697315 0.80070858 0.81182116 0.80639853 0.79962273\n",
      " 0.79799745 0.78580012 0.75298379 0.80206212 0.80151791 0.73590584\n",
      " 0.78389611 0.79555585 0.74348656 0.80884197 0.80043316 0.75922347\n",
      " 0.80314429 0.79176475 0.77305674 0.78200167 0.79636224 0.76871776\n",
      " 0.78143613 0.82130883 0.80585873 0.81670803 0.81968428 0.81127842\n",
      " 0.82049729 0.82428728 0.80314466 0.76112711 0.82700503 0.8061301\n",
      " 0.78281321 0.82727346 0.81317617 0.8085603  0.8324295  0.81534383\n",
      " 0.81073972 0.81778396 0.782269   0.82076609 0.81019    0.78579902\n",
      " 0.82916938 0.81751185 0.78037124 0.7749556  0.82483481 0.79393314\n",
      " 0.78524488 0.82212699 0.79473696 0.80341677 0.82239615 0.80748034\n",
      " 0.80613084 0.79148971 0.76655194 0.81806047 0.80802565 0.74972734\n",
      " 0.80125279 0.7760374  0.75053336 0.78634029 0.80341125 0.77196795\n",
      " 0.79066603 0.80775833 0.77332774 0.80532077 0.80558148 0.76708181]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.63129127\n",
      "Validation score: 0.326558\n",
      "Iteration 2, loss = 1.12056612\n",
      "Validation score: 0.288618\n",
      "Iteration 3, loss = 0.94868607\n",
      "Validation score: 0.472900\n",
      "Iteration 4, loss = 0.76849252\n",
      "Validation score: 0.712737\n",
      "Iteration 5, loss = 0.64239932\n",
      "Validation score: 0.739837\n",
      "Iteration 6, loss = 0.58789145\n",
      "Validation score: 0.745257\n",
      "Iteration 7, loss = 0.50836185\n",
      "Validation score: 0.769648\n",
      "Iteration 8, loss = 0.44111627\n",
      "Validation score: 0.760163\n",
      "Iteration 9, loss = 0.36683207\n",
      "Validation score: 0.710027\n",
      "Iteration 10, loss = 0.37076293\n",
      "Validation score: 0.827913\n",
      "Iteration 11, loss = 0.32760500\n",
      "Validation score: 0.825203\n",
      "Iteration 12, loss = 0.35472833\n",
      "Validation score: 0.411924\n",
      "Iteration 13, loss = 0.58741363\n",
      "Validation score: 0.643631\n",
      "Iteration 14, loss = 0.40432416\n",
      "Validation score: 0.520325\n",
      "Iteration 15, loss = 0.28786891\n",
      "Validation score: 0.509485\n",
      "Iteration 16, loss = 0.26738734\n",
      "Validation score: 0.826558\n",
      "Iteration 17, loss = 0.18056639\n",
      "Validation score: 0.776423\n",
      "Iteration 18, loss = 0.10524610\n",
      "Validation score: 0.661247\n",
      "Iteration 19, loss = 0.28139982\n",
      "Validation score: 0.676152\n",
      "Iteration 20, loss = 0.11775805\n",
      "Validation score: 0.390244\n",
      "Iteration 21, loss = 0.49698293\n",
      "Validation score: 0.829268\n",
      "Iteration 22, loss = 0.20749778\n",
      "Validation score: 0.785908\n",
      "Iteration 23, loss = 0.07815428\n",
      "Validation score: 0.848238\n",
      "Iteration 24, loss = 0.05328746\n",
      "Validation score: 0.834688\n",
      "Iteration 25, loss = 0.02461209\n",
      "Validation score: 0.856369\n",
      "Iteration 26, loss = 0.01639118\n",
      "Validation score: 0.856369\n",
      "Iteration 27, loss = 0.01190587\n",
      "Validation score: 0.864499\n",
      "Iteration 28, loss = 0.00909311\n",
      "Validation score: 0.845528\n",
      "Iteration 29, loss = 0.00752654\n",
      "Validation score: 0.860434\n",
      "Iteration 30, loss = 0.00614145\n",
      "Validation score: 0.857724\n",
      "Iteration 31, loss = 0.00532540\n",
      "Validation score: 0.853659\n",
      "Iteration 32, loss = 0.00497023\n",
      "Validation score: 0.841463\n",
      "Iteration 33, loss = 0.00439936\n",
      "Validation score: 0.855014\n",
      "Iteration 34, loss = 0.00379057\n",
      "Validation score: 0.856369\n",
      "Iteration 35, loss = 0.00340970\n",
      "Validation score: 0.860434\n",
      "Iteration 36, loss = 0.00314528\n",
      "Validation score: 0.871274\n",
      "Iteration 37, loss = 0.00297159\n",
      "Validation score: 0.865854\n",
      "Iteration 38, loss = 0.00272548\n",
      "Validation score: 0.867209\n",
      "Iteration 39, loss = 0.00253503\n",
      "Validation score: 0.859079\n",
      "Iteration 40, loss = 0.00240818\n",
      "Validation score: 0.861789\n",
      "Iteration 41, loss = 0.00223211\n",
      "Validation score: 0.865854\n",
      "Iteration 42, loss = 0.00211805\n",
      "Validation score: 0.852304\n",
      "Iteration 43, loss = 0.00202784\n",
      "Validation score: 0.864499\n",
      "Iteration 44, loss = 0.00190229\n",
      "Validation score: 0.857724\n",
      "Iteration 45, loss = 0.00181704\n",
      "Validation score: 0.860434\n",
      "Iteration 46, loss = 0.00172325\n",
      "Validation score: 0.863144\n",
      "Iteration 47, loss = 0.00164739\n",
      "Validation score: 0.861789\n",
      "Iteration 48, loss = 0.00158065\n",
      "Validation score: 0.859079\n",
      "Iteration 49, loss = 0.00151153\n",
      "Validation score: 0.853659\n",
      "Iteration 50, loss = 0.00144509\n",
      "Validation score: 0.865854\n",
      "Iteration 51, loss = 0.00139571\n",
      "Validation score: 0.861789\n",
      "Iteration 52, loss = 0.00134137\n",
      "Validation score: 0.864499\n",
      "Iteration 53, loss = 0.00129653\n",
      "Validation score: 0.860434\n",
      "Iteration 54, loss = 0.00124857\n",
      "Validation score: 0.864499\n",
      "Iteration 55, loss = 0.00120660\n",
      "Validation score: 0.859079\n",
      "Iteration 56, loss = 0.00116489\n",
      "Validation score: 0.863144\n",
      "Iteration 57, loss = 0.00112867\n",
      "Validation score: 0.860434\n",
      "Iteration 58, loss = 0.00109213\n",
      "Validation score: 0.861789\n",
      "Iteration 59, loss = 0.00105869\n",
      "Validation score: 0.864499\n",
      "Iteration 60, loss = 0.00102828\n",
      "Validation score: 0.861789\n",
      "Iteration 61, loss = 0.00100000\n",
      "Validation score: 0.857724\n",
      "Iteration 62, loss = 0.00097275\n",
      "Validation score: 0.861789\n",
      "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
      "Mejores hiperparámetros: {'activation': 'relu', 'batch_size': 32, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.1}\n",
      "Iteration 1, loss = 1.63129127\n",
      "Validation score: 0.326558\n",
      "Iteration 2, loss = 1.12056612\n",
      "Validation score: 0.288618\n",
      "Iteration 3, loss = 0.94868607\n",
      "Validation score: 0.472900\n",
      "Iteration 4, loss = 0.76849252\n",
      "Validation score: 0.712737\n",
      "Iteration 5, loss = 0.64239932\n",
      "Validation score: 0.739837\n",
      "Iteration 6, loss = 0.58789145\n",
      "Validation score: 0.745257\n",
      "Iteration 7, loss = 0.50836185\n",
      "Validation score: 0.769648\n",
      "Iteration 8, loss = 0.44111627\n",
      "Validation score: 0.760163\n",
      "Iteration 9, loss = 0.36683207\n",
      "Validation score: 0.710027\n",
      "Iteration 10, loss = 0.37076293\n",
      "Validation score: 0.827913\n",
      "Iteration 11, loss = 0.32760500\n",
      "Validation score: 0.825203\n",
      "Iteration 12, loss = 0.35472833\n",
      "Validation score: 0.411924\n",
      "Iteration 13, loss = 0.58741363\n",
      "Validation score: 0.643631\n",
      "Iteration 14, loss = 0.40432416\n",
      "Validation score: 0.520325\n",
      "Iteration 15, loss = 0.28786891\n",
      "Validation score: 0.509485\n",
      "Iteration 16, loss = 0.26738734\n",
      "Validation score: 0.826558\n",
      "Iteration 17, loss = 0.18056639\n",
      "Validation score: 0.776423\n",
      "Iteration 18, loss = 0.10524610\n",
      "Validation score: 0.661247\n",
      "Iteration 19, loss = 0.28139982\n",
      "Validation score: 0.676152\n",
      "Iteration 20, loss = 0.11775805\n",
      "Validation score: 0.390244\n",
      "Iteration 21, loss = 0.49698293\n",
      "Validation score: 0.829268\n",
      "Iteration 22, loss = 0.20749778\n",
      "Validation score: 0.785908\n",
      "Iteration 23, loss = 0.07815428\n",
      "Validation score: 0.848238\n",
      "Iteration 24, loss = 0.05328746\n",
      "Validation score: 0.834688\n",
      "Iteration 25, loss = 0.02461209\n",
      "Validation score: 0.856369\n",
      "Iteration 26, loss = 0.01639118\n",
      "Validation score: 0.856369\n",
      "Iteration 27, loss = 0.01190587\n",
      "Validation score: 0.864499\n",
      "Iteration 28, loss = 0.00909311\n",
      "Validation score: 0.845528\n",
      "Iteration 29, loss = 0.00752654\n",
      "Validation score: 0.860434\n",
      "Iteration 30, loss = 0.00614145\n",
      "Validation score: 0.857724\n",
      "Iteration 31, loss = 0.00532540\n",
      "Validation score: 0.853659\n",
      "Iteration 32, loss = 0.00497023\n",
      "Validation score: 0.841463\n",
      "Iteration 33, loss = 0.00439936\n",
      "Validation score: 0.855014\n",
      "Iteration 34, loss = 0.00379057\n",
      "Validation score: 0.856369\n",
      "Iteration 35, loss = 0.00340970\n",
      "Validation score: 0.860434\n",
      "Iteration 36, loss = 0.00314528\n",
      "Validation score: 0.871274\n",
      "Iteration 37, loss = 0.00297159\n",
      "Validation score: 0.865854\n",
      "Iteration 38, loss = 0.00272548\n",
      "Validation score: 0.867209\n",
      "Iteration 39, loss = 0.00253503\n",
      "Validation score: 0.859079\n",
      "Iteration 40, loss = 0.00240818\n",
      "Validation score: 0.861789\n",
      "Iteration 41, loss = 0.00223211\n",
      "Validation score: 0.865854\n",
      "Iteration 42, loss = 0.00211805\n",
      "Validation score: 0.852304\n",
      "Iteration 43, loss = 0.00202784\n",
      "Validation score: 0.864499\n",
      "Iteration 44, loss = 0.00190229\n",
      "Validation score: 0.857724\n",
      "Iteration 45, loss = 0.00181704\n",
      "Validation score: 0.860434\n",
      "Iteration 46, loss = 0.00172325\n",
      "Validation score: 0.863144\n",
      "Iteration 47, loss = 0.00164739\n",
      "Validation score: 0.861789\n",
      "Iteration 48, loss = 0.00158065\n",
      "Validation score: 0.859079\n",
      "Iteration 49, loss = 0.00151153\n",
      "Validation score: 0.853659\n",
      "Iteration 50, loss = 0.00144509\n",
      "Validation score: 0.865854\n",
      "Iteration 51, loss = 0.00139571\n",
      "Validation score: 0.861789\n",
      "Iteration 52, loss = 0.00134137\n",
      "Validation score: 0.864499\n",
      "Iteration 53, loss = 0.00129653\n",
      "Validation score: 0.860434\n",
      "Iteration 54, loss = 0.00124857\n",
      "Validation score: 0.864499\n",
      "Iteration 55, loss = 0.00120660\n",
      "Validation score: 0.859079\n",
      "Iteration 56, loss = 0.00116489\n",
      "Validation score: 0.863144\n",
      "Iteration 57, loss = 0.00112867\n",
      "Validation score: 0.860434\n",
      "Iteration 58, loss = 0.00109213\n",
      "Validation score: 0.861789\n",
      "Iteration 59, loss = 0.00105869\n",
      "Validation score: 0.864499\n",
      "Iteration 60, loss = 0.00102828\n",
      "Validation score: 0.861789\n",
      "Iteration 61, loss = 0.00100000\n",
      "Validation score: 0.857724\n",
      "Iteration 62, loss = 0.00097275\n",
      "Validation score: 0.861789\n",
      "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
      "Precisión del modelo: 0.8266522210184182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.66      0.77      0.71       101\n",
      "     disgust       0.69      0.62      0.65       112\n",
      "        fear       0.79      0.83      0.81       156\n",
      "       happy       0.95      0.96      0.96       149\n",
      "     neutral       0.91      0.88      0.89       153\n",
      "         sad       0.80      0.76      0.78       119\n",
      "    surprise       0.94      0.88      0.91       133\n",
      "\n",
      "    accuracy                           0.83       923\n",
      "   macro avg       0.82      0.82      0.82       923\n",
      "weighted avg       0.83      0.83      0.83       923\n",
      "\n",
      "CPU times: total: 1min 50s\n",
      "Wall time: 2h 20min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define el modelo de Red Neuronal\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                    activation='logistic',\n",
    "                    solver='sgd',\n",
    "                    alpha=0,\n",
    "                    learning_rate='constant',\n",
    "                    max_iter=10000,\n",
    "                    tol=1e-4,\n",
    "                    verbose=True,\n",
    "                    momentum=0,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction = 0.2,\n",
    "                    n_iter_no_change=25,\n",
    "                    random_state=42)\n",
    "\n",
    "# Define una cuadrícula de hiperparámetros que deseas explorar\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.2,0.1,0.01],\n",
    "    'batch_size': [32,128,512],\n",
    "    'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'hidden_layer_sizes' : [(50,), (100,), (150,), (50, 50), (100, 100), (150, 150)]\n",
    "}\n",
    "\n",
    "# Realiza la búsqueda en cuadrícula con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, scoring='accuracy', verbose=10,n_jobs=12)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los mejores hiperparámetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "\n",
    "# Entrena el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en el conjunto de prueba\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados** \n",
    "\n",
    "Precisión del modelo: 0.8266522210184182\n",
    "- 'activation': 'relu', \n",
    "- 'batch_size': 32, \n",
    "- 'hidden_layer_sizes': (150, 150), \n",
    "- 'learning_rate_init': 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tercero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Iteration 1, loss = 1.66731520\n",
      "Validation score: 0.517615\n",
      "Iteration 2, loss = 1.17159039\n",
      "Validation score: 0.677507\n",
      "Iteration 3, loss = 0.90054906\n",
      "Validation score: 0.677507\n",
      "Iteration 4, loss = 0.79441614\n",
      "Validation score: 0.528455\n",
      "Iteration 5, loss = 0.66462087\n",
      "Validation score: 0.691057\n",
      "Iteration 6, loss = 0.55706461\n",
      "Validation score: 0.609756\n",
      "Iteration 7, loss = 0.48991086\n",
      "Validation score: 0.764228\n",
      "Iteration 8, loss = 0.46645658\n",
      "Validation score: 0.661247\n",
      "Iteration 9, loss = 1.01795763\n",
      "Validation score: 0.371274\n",
      "Iteration 10, loss = 0.56822382\n",
      "Validation score: 0.707317\n",
      "Iteration 11, loss = 0.47515479\n",
      "Validation score: 0.650407\n",
      "Iteration 12, loss = 0.36321238\n",
      "Validation score: 0.566396\n",
      "Iteration 13, loss = 0.34837084\n",
      "Validation score: 0.779133\n",
      "Iteration 14, loss = 0.36646717\n",
      "Validation score: 0.757453\n",
      "Iteration 15, loss = 0.22720211\n",
      "Validation score: 0.823848\n",
      "Iteration 16, loss = 0.19869274\n",
      "Validation score: 0.817073\n",
      "Iteration 17, loss = 0.16875163\n",
      "Validation score: 0.833333\n",
      "Iteration 18, loss = 0.10297472\n",
      "Validation score: 0.730352\n",
      "Iteration 19, loss = 0.15140441\n",
      "Validation score: 0.695122\n",
      "Iteration 20, loss = 0.51135236\n",
      "Validation score: 0.615176\n",
      "Iteration 21, loss = 0.58151822\n",
      "Validation score: 0.794038\n",
      "Iteration 22, loss = 0.33169853\n",
      "Validation score: 0.833333\n",
      "Iteration 23, loss = 0.25928611\n",
      "Validation score: 0.850949\n",
      "Iteration 24, loss = 0.28047356\n",
      "Validation score: 0.760163\n",
      "Iteration 25, loss = 0.24797570\n",
      "Validation score: 0.554201\n",
      "Iteration 26, loss = 0.20324043\n",
      "Validation score: 0.814363\n",
      "Iteration 27, loss = 0.07764254\n",
      "Validation score: 0.796748\n",
      "Iteration 28, loss = 0.14829971\n",
      "Validation score: 0.762873\n",
      "Iteration 29, loss = 0.19731617\n",
      "Validation score: 0.836043\n",
      "Iteration 30, loss = 0.06618506\n",
      "Validation score: 0.840108\n",
      "Iteration 31, loss = 0.04083467\n",
      "Validation score: 0.855014\n",
      "Iteration 32, loss = 0.00519181\n",
      "Validation score: 0.855014\n",
      "Iteration 33, loss = 0.00234589\n",
      "Validation score: 0.856369\n",
      "Iteration 34, loss = 0.00152031\n",
      "Validation score: 0.853659\n",
      "Iteration 35, loss = 0.00105610\n",
      "Validation score: 0.853659\n",
      "Iteration 36, loss = 0.00085156\n",
      "Validation score: 0.852304\n",
      "Iteration 37, loss = 0.00070659\n",
      "Validation score: 0.852304\n",
      "Iteration 38, loss = 0.00060872\n",
      "Validation score: 0.855014\n",
      "Iteration 39, loss = 0.00053026\n",
      "Validation score: 0.853659\n",
      "Iteration 40, loss = 0.00047458\n",
      "Validation score: 0.855014\n",
      "Iteration 41, loss = 0.00042448\n",
      "Validation score: 0.853659\n",
      "Iteration 42, loss = 0.00038594\n",
      "Validation score: 0.853659\n",
      "Iteration 43, loss = 0.00035235\n",
      "Validation score: 0.855014\n",
      "Iteration 44, loss = 0.00032425\n",
      "Validation score: 0.852304\n",
      "Iteration 45, loss = 0.00030119\n",
      "Validation score: 0.853659\n",
      "Iteration 46, loss = 0.00027976\n",
      "Validation score: 0.853659\n",
      "Iteration 47, loss = 0.00026190\n",
      "Validation score: 0.853659\n",
      "Iteration 48, loss = 0.00024456\n",
      "Validation score: 0.853659\n",
      "Iteration 49, loss = 0.00022936\n",
      "Validation score: 0.852304\n",
      "Iteration 50, loss = 0.00021748\n",
      "Validation score: 0.853659\n",
      "Iteration 51, loss = 0.00020532\n",
      "Validation score: 0.853659\n",
      "Iteration 52, loss = 0.00019553\n",
      "Validation score: 0.853659\n",
      "Iteration 53, loss = 0.00018605\n",
      "Validation score: 0.853659\n",
      "Iteration 54, loss = 0.00017749\n",
      "Validation score: 0.853659\n",
      "Iteration 55, loss = 0.00016931\n",
      "Validation score: 0.853659\n",
      "Iteration 56, loss = 0.00016229\n",
      "Validation score: 0.853659\n",
      "Iteration 57, loss = 0.00015545\n",
      "Validation score: 0.853659\n",
      "Iteration 58, loss = 0.00014920\n",
      "Validation score: 0.853659\n",
      "Iteration 59, loss = 0.00014352\n",
      "Validation score: 0.853659\n",
      "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
      "Mejores hiperparámetros: {'batch_size': 16, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.1}\n",
      "Iteration 1, loss = 1.66731520\n",
      "Validation score: 0.517615\n",
      "Iteration 2, loss = 1.17159039\n",
      "Validation score: 0.677507\n",
      "Iteration 3, loss = 0.90054906\n",
      "Validation score: 0.677507\n",
      "Iteration 4, loss = 0.79441614\n",
      "Validation score: 0.528455\n",
      "Iteration 5, loss = 0.66462087\n",
      "Validation score: 0.691057\n",
      "Iteration 6, loss = 0.55706461\n",
      "Validation score: 0.609756\n",
      "Iteration 7, loss = 0.48991086\n",
      "Validation score: 0.764228\n",
      "Iteration 8, loss = 0.46645658\n",
      "Validation score: 0.661247\n",
      "Iteration 9, loss = 1.01795763\n",
      "Validation score: 0.371274\n",
      "Iteration 10, loss = 0.56822382\n",
      "Validation score: 0.707317\n",
      "Iteration 11, loss = 0.47515479\n",
      "Validation score: 0.650407\n",
      "Iteration 12, loss = 0.36321238\n",
      "Validation score: 0.566396\n",
      "Iteration 13, loss = 0.34837084\n",
      "Validation score: 0.779133\n",
      "Iteration 14, loss = 0.36646717\n",
      "Validation score: 0.757453\n",
      "Iteration 15, loss = 0.22720211\n",
      "Validation score: 0.823848\n",
      "Iteration 16, loss = 0.19869274\n",
      "Validation score: 0.817073\n",
      "Iteration 17, loss = 0.16875163\n",
      "Validation score: 0.833333\n",
      "Iteration 18, loss = 0.10297472\n",
      "Validation score: 0.730352\n",
      "Iteration 19, loss = 0.15140441\n",
      "Validation score: 0.695122\n",
      "Iteration 20, loss = 0.51135236\n",
      "Validation score: 0.615176\n",
      "Iteration 21, loss = 0.58151822\n",
      "Validation score: 0.794038\n",
      "Iteration 22, loss = 0.33169853\n",
      "Validation score: 0.833333\n",
      "Iteration 23, loss = 0.25928611\n",
      "Validation score: 0.850949\n",
      "Iteration 24, loss = 0.28047356\n",
      "Validation score: 0.760163\n",
      "Iteration 25, loss = 0.24797570\n",
      "Validation score: 0.554201\n",
      "Iteration 26, loss = 0.20324043\n",
      "Validation score: 0.814363\n",
      "Iteration 27, loss = 0.07764254\n",
      "Validation score: 0.796748\n",
      "Iteration 28, loss = 0.14829971\n",
      "Validation score: 0.762873\n",
      "Iteration 29, loss = 0.19731617\n",
      "Validation score: 0.836043\n",
      "Iteration 30, loss = 0.06618506\n",
      "Validation score: 0.840108\n",
      "Iteration 31, loss = 0.04083467\n",
      "Validation score: 0.855014\n",
      "Iteration 32, loss = 0.00519181\n",
      "Validation score: 0.855014\n",
      "Iteration 33, loss = 0.00234589\n",
      "Validation score: 0.856369\n",
      "Iteration 34, loss = 0.00152031\n",
      "Validation score: 0.853659\n",
      "Iteration 35, loss = 0.00105610\n",
      "Validation score: 0.853659\n",
      "Iteration 36, loss = 0.00085156\n",
      "Validation score: 0.852304\n",
      "Iteration 37, loss = 0.00070659\n",
      "Validation score: 0.852304\n",
      "Iteration 38, loss = 0.00060872\n",
      "Validation score: 0.855014\n",
      "Iteration 39, loss = 0.00053026\n",
      "Validation score: 0.853659\n",
      "Iteration 40, loss = 0.00047458\n",
      "Validation score: 0.855014\n",
      "Iteration 41, loss = 0.00042448\n",
      "Validation score: 0.853659\n",
      "Iteration 42, loss = 0.00038594\n",
      "Validation score: 0.853659\n",
      "Iteration 43, loss = 0.00035235\n",
      "Validation score: 0.855014\n",
      "Iteration 44, loss = 0.00032425\n",
      "Validation score: 0.852304\n",
      "Iteration 45, loss = 0.00030119\n",
      "Validation score: 0.853659\n",
      "Iteration 46, loss = 0.00027976\n",
      "Validation score: 0.853659\n",
      "Iteration 47, loss = 0.00026190\n",
      "Validation score: 0.853659\n",
      "Iteration 48, loss = 0.00024456\n",
      "Validation score: 0.853659\n",
      "Iteration 49, loss = 0.00022936\n",
      "Validation score: 0.852304\n",
      "Iteration 50, loss = 0.00021748\n",
      "Validation score: 0.853659\n",
      "Iteration 51, loss = 0.00020532\n",
      "Validation score: 0.853659\n",
      "Iteration 52, loss = 0.00019553\n",
      "Validation score: 0.853659\n",
      "Iteration 53, loss = 0.00018605\n",
      "Validation score: 0.853659\n",
      "Iteration 54, loss = 0.00017749\n",
      "Validation score: 0.853659\n",
      "Iteration 55, loss = 0.00016931\n",
      "Validation score: 0.853659\n",
      "Iteration 56, loss = 0.00016229\n",
      "Validation score: 0.853659\n",
      "Iteration 57, loss = 0.00015545\n",
      "Validation score: 0.853659\n",
      "Iteration 58, loss = 0.00014920\n",
      "Validation score: 0.853659\n",
      "Iteration 59, loss = 0.00014352\n",
      "Validation score: 0.853659\n",
      "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n",
      "Precisión del modelo: 0.8331527627302275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.78      0.73      0.76       101\n",
      "     disgust       0.64      0.71      0.67       112\n",
      "        fear       0.77      0.85      0.81       156\n",
      "       happy       0.97      0.96      0.97       149\n",
      "     neutral       0.90      0.87      0.89       153\n",
      "         sad       0.81      0.75      0.78       119\n",
      "    surprise       0.93      0.89      0.91       133\n",
      "\n",
      "    accuracy                           0.83       923\n",
      "   macro avg       0.83      0.82      0.82       923\n",
      "weighted avg       0.84      0.83      0.83       923\n",
      "\n",
      "CPU times: total: 1min 13s\n",
      "Wall time: 1h 17min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define el modelo de Red Neuronal\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                    activation='relu',\n",
    "                    solver='sgd',\n",
    "                    alpha=0,\n",
    "                    learning_rate='constant',\n",
    "                    max_iter=10000,\n",
    "                    tol=1e-4,\n",
    "                    verbose=True,\n",
    "                    momentum=0,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction = 0.2,\n",
    "                    n_iter_no_change=25,\n",
    "                    random_state=42)\n",
    "\n",
    "# Define una cuadrícula de hiperparámetros que deseas explorar\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.15,0.1,0.05],\n",
    "    'batch_size': [16,32,64],\n",
    "    'hidden_layer_sizes' : [(200,), (150, 150), (200, 200), (50, 50, 50), (100, 100, 100), (150, 150,150)]\n",
    "}\n",
    "\n",
    "# Realiza la búsqueda en cuadrícula con validación cruzada\n",
    "grid_search_thethird = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, scoring='accuracy', verbose=10,n_jobs=12)\n",
    "grid_search_thethird.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los mejores hiperparámetros encontrados\n",
    "best_params = grid_search_thethird.best_params_\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "\n",
    "# Entrena el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "best_rf_classifier = grid_search_thethird.best_estimator_\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en el conjunto de prueba\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados** \n",
    "\n",
    "Precisión del modelo: 0.8331527627302275\n",
    "- 'activation': 'relu', \n",
    "- 'batch_size': 16, \n",
    "- 'hidden_layer_sizes': (150, 150,150), \n",
    "- 'learning_rate_init': 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean test score: 0.836 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.826 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.820 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.825 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.829 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.827 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.819 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.835 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.824 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.795 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.819 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.825 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.803 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.824 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.828 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.823 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.837 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.827 with parameters: {'batch_size': 16, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.830 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.822 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.819 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.827 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.832 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.823 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.832 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.832 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.821 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.793 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.809 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.824 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.808 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.823 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.818 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.810 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.834 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.826 with parameters: {'batch_size': 32, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.824 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.823 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.818 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (200,), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.815 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.829 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.815 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (150, 150), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.833 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.828 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.819 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (200, 200), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.783 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.806 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.813 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.803 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.825 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.816 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (100, 100, 100), 'learning_rate_init': 0.05}\n",
      " Mean test score: 0.814 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.15}\n",
      " Mean test score: 0.828 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.1}\n",
      " Mean test score: 0.820 with parameters: {'batch_size': 64, 'hidden_layer_sizes': (150, 150, 150), 'learning_rate_init': 0.05}\n"
     ]
    }
   ],
   "source": [
    "results = grid_search_thethird.cv_results_\n",
    "acc_e =[]\n",
    "acc_t=[]\n",
    "n_nnn=[]\n",
    "i=1\n",
    "for  mean_test_score, params in zip( results['mean_test_score'], results['params']):\n",
    "    acc_t.append(mean_test_score)\n",
    "    n_nnn.append(i)\n",
    "    print(f\" Mean test score: {mean_test_score:.3f} with parameters: {params}\")\n",
    "    i=i+2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuarto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define el modelo de Red Neuronal\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                    activation='relu',\n",
    "                    solver='sgd',\n",
    "                    alpha=0,\n",
    "                    learning_rate='constant',\n",
    "                    max_iter=10000,\n",
    "                    tol=1e-4,\n",
    "                    verbose=True,\n",
    "                    momentum=0,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction = 0.2,\n",
    "                    n_iter_no_change=25,\n",
    "                    random_state=42)\n",
    "\n",
    "# Define una cuadrícula de hiperparámetros que deseas explorar\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.15,0.1,0.05],\n",
    "    'batch_size': [16,32,64],\n",
    "    'hidden_layer_sizes' : [(200,), (150, 150), (200, 200), (50, 50, 50), (100, 100, 100), (150, 150,150)]\n",
    "}\n",
    "\n",
    "# Realiza la búsqueda en cuadrícula con validación cruzada\n",
    "grid_search_theforth = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, scoring='accuracy', verbose=10,n_jobs=12)\n",
    "grid_search_theforth.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los mejores hiperparámetros encontrados\n",
    "best_params = grid_search_theforth.best_params_\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "\n",
    "# Entrena el modelo con los mejores hiperparámetros en todo el conjunto de entrenamiento\n",
    "best_rf_classifier = grid_search_theforth.best_estimator_\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en el conjunto de prueba\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados** \n",
    "\n",
    "Precisión del modelo: 0.8331527627302275\n",
    "- 'activation': 'relu', \n",
    "- 'batch_size': 16, \n",
    "- 'hidden_layer_sizes': (150, 150,150), \n",
    "- 'learning_rate_init': 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
